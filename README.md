# ğŸ“’ Obsidian ML Notes Repository

Welcome to my **Obsidian Machine Learning Notes** repository! This repository is a structured collection of my learnings, experiments, and research in **Machine Learning (ML)**, ranging from fundamental concepts to advanced implementations.

## ğŸš€ About
This repository serves as:
- A **personal knowledge base** for ML concepts, best practices, and methodologies.
- A **reference guide** to revisit key ideas in Deep Learning, Neural Networks, and related fields.
- A **learning journal** to track progress and consolidate knowledge through well-organized notes.

## ğŸ“‚ Folder Structure

Below is an overview of the repositoryâ€™s thematic folder structure:


```
ğŸ“‚ obsidian_ml_notes/
â”œâ”€â”€ ğŸ“ Deep Learning & Neural Networks/
â”‚   â”œâ”€â”€ ğŸ“ Layers_&_Architectures/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Activation Functions.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Bidirectional GRU Layer.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Dropout for Regularization.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Global Max Pooling Layer.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ GRU Layer.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Multi-Head Attention.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ RNN.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ Transformers.md
â”‚   â”œâ”€â”€ ğŸ“ Neural_Networks/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Neural Networks history.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ Neural Networks.md
â”‚   â””â”€â”€ ğŸ“ Training/
â”‚       â”œâ”€â”€ ğŸ“„ Batch Size.md
â”‚       â”œâ”€â”€ ğŸ“„ Early Stopping.md
â”‚       â”œâ”€â”€ ğŸ“„ Hyperparameter Tuning.md
â”‚       â”œâ”€â”€ ğŸ“„ Learning Rate.md
â”‚       â”œâ”€â”€ ğŸ“„ Loss Function.md
â”‚       â”œâ”€â”€ ğŸ“„ Optimizer.md
â”‚       â”œâ”€â”€ ğŸ“„ Regularization.md
â”‚       â””â”€â”€ ğŸ“„ Training Loop.md
â”œâ”€â”€ ğŸ“ Evaluation/
â”‚   â”œâ”€â”€ ğŸ“„ Cross-Validation.md
â”‚   â”œâ”€â”€ ğŸ“„ Model Evaluation.md
â”‚   â”œâ”€â”€ ğŸ“„ Overfitting and Underfitting.md
â”‚   â””â”€â”€ ğŸ“„ Performance Metrics.md
â”œâ”€â”€ ğŸ“ Fundamentals/
â”‚   â”œâ”€â”€ ğŸ“ Data_Processing_&_Statistics/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Class Imbalance Handling.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Data Cleaning.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Data Preprocessing.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ EDA.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“ Feature_Engineering/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Better Alternatives to One-Hot Encoding.md
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Dimensionality Reduction.md
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Feature Engineering.md
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Feature Scaling.md
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ Standardization (Z-Score Scaling).md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Handling Outliers.md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ PCA.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ Visualization Techniques.md
â”‚   â””â”€â”€ ğŸ“ Mathematical_Foundations/
â”‚       â”œâ”€â”€ ğŸ“„ Eigenvalues & Eigenvectors.md
â”‚       â”œâ”€â”€ ğŸ“„ Eigenvalues and eigenvectors (linear algebra).md
â”‚       â””â”€â”€ ğŸ“„ Mathematical Foundations of Random Forests.md
â”œâ”€â”€ ğŸ“ Machine_Learning_Algorithms/
â”‚   â”œâ”€â”€ ğŸ“ Ensemble_Methods/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Bootstrap Sampling.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ Ensemble Learning.md
â”‚   â”œâ”€â”€ ğŸ“„ Machine Learning Subfields.md
â”‚   â”œâ”€â”€ ğŸ“„ Models.md
â”‚   â””â”€â”€ ğŸ“ Traditional_Models/
â”‚       â”œâ”€â”€ ğŸ“„ Gini Impurity.md
â”‚       â”œâ”€â”€ ğŸ“„ K-Means.md
â”‚       â”œâ”€â”€ ğŸ“„ NaÃ¯ve Bayes.md
â”‚       â”œâ”€â”€ ğŸ“„ Random Forest.md
â”‚       â””â”€â”€ ğŸ“„ SVM.md
â”œâ”€â”€ ğŸ“ Natural_Language_Processing/
â”‚   â”œâ”€â”€ ğŸ“„ Embedding.md
â”‚   â”œâ”€â”€ ğŸ“„ NLP glossary.md
â”‚   â”œâ”€â”€ ğŸ“„ Padding.md
â”‚   â””â”€â”€ ğŸ“„ Temperature and top P in Transformers.md
â”œâ”€â”€ ğŸ“ Reinforcement_Learning/
â”‚   â””â”€â”€ ğŸ“„ The Reinforcement Learning for Deepseek r1.md
â”œâ”€â”€ ğŸ“ Workflow & Projects/
â”‚   â”œâ”€â”€ ğŸ“ Case_Studies/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Building a Fraud Detection System..md
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ Machine Learning workflow on Garmin dataset.md
â”‚   â”‚   â””â”€â”€ ğŸ“„ Titanic Survival Prediction Story ğŸš¢ğŸŒ².md
â”‚   â””â”€â”€ ğŸ“ General_Workflow/
â”‚       â””â”€â”€ ğŸ“„ Machine Learning Workflow, general purpose.md
â”œâ”€â”€ ğŸ”— Usefull references.md
â””â”€â”€ ğŸ“œ LICENSE

```

## ğŸ› ï¸ How to Use
1. Clone the repository:
   ```sh
   git clone https://github.com/yourusername/obsidian-ml-notes.git
   ```
2. Open in [Obsidian](https://obsidian.md/).
3. Explore, edit, and contribute to your learning journey!

## ğŸ” Topics Covered
- **Deep Learning & Neural Networks:** Layers, architectures, training methods, and historical insights.
- **Evaluation:** Techniques for model validation, cross-validation, and performance measurement.
- **Fundamentals:** Data processing, statistics, feature engineering, and core mathematical foundations.
- **Machine Learning Algorithms:** Traditional models, ensemble methods, and subfield breakdowns.
- **Natural Language Processing:** Key NLP concepts including embeddings and transformer-related techniques.
- **Reinforcement Learning:** Advanced methods and case studies.
- **Workflow & Projects:** End-to-end ML workflows and real-world case studies.
- **Additional References:** Curated useful references to complement your learning journey.

## ğŸ—ï¸ Future Improvements
- Expand notes with more **real-world case studies**.
- Add **code snippets and implementation guides**.
- Include **interactive Jupyter Notebooks**.

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“¬ Contact
Feel free to connect via **GitHub Issues** or reach out if you have insights to share!

Happy Learning! ğŸš€
